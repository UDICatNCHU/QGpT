# -*- coding: utf-8 -*-
"""
QGpT: Improving Table Retrieval with Question Generation from Partial Tables
Corpus Embedding Builder

This script builds vector embeddings for table corpora using the QGpT framework.
It processes table data from JSON files and creates vector databases with corpus-specific naming.

Usage:
    python corpus_embedding_builder.py [corpus_file_path]
    python corpus_embedding_builder.py --list  # åˆ—å‡ºæ‰€æœ‰å¯ç”¨èªæ–™åº«
    python corpus_embedding_builder.py --all   # å»ºç«‹æ‰€æœ‰èªæ–™åº«çš„ embedding
    python corpus_embedding_builder.py --scan-dir ./data  # éæ­¸æƒæç›®éŒ„å»ºç«‹ embedding
    python corpus_embedding_builder.py --scan-dir ./Corpora/Table1_mimo_table_length_variation  # éæ­¸æƒæç›®å»ºéŒ„ç«‹ embedding

Author: QGpT Research Team
Repository: https://github.com/UDICatNCHU/QGpT
"""

import argparse
import sys
from pathlib import Path
from typing import List, Dict, Optional
from pymilvus import MilvusClient

from utils import (
    load_json_dataset, 
    preprocess_text, 
    extract_corpus_name_from_path,
    generate_db_name,
    generate_collection_name,
    get_corpus_files,
    validate_corpus_structure
)
from embedding_models import EmbeddingModel, MODELS

class CorpusEmbeddingBuilder:
    """èªæ–™åº«åµŒå…¥å‘é‡å»ºç«‹å™¨"""
    
    def __init__(self, model="bge_m3_flag", embedding_dim=1024):
        """
        åˆå§‹åŒ–å»ºç«‹å™¨
        
        Args:
            embedding_dim: åµŒå…¥å‘é‡ç¶­åº¦ (BGE-M3 è¼¸å‡º 1024 ç¶­)
        """
        self.embedding_dim = embedding_dim
        if model == "jina_colbert_v2" and embedding_dim != 128:
            print("âš ï¸  Jina ColBERT v2 åµŒå…¥å‘é‡ç¶­åº¦å›ºå®šç‚º 128ï¼Œå°‡å¿½ç•¥ --dim åƒæ•¸")
            self.embedding_dim = 128

        print(f"ğŸ”„ åˆå§‹åŒ– {model} ...")
        self.model_name = model
        self.embedding_fn = MODELS.get(model)()

        print(f"âœ… {model} è¼‰å…¥å®Œæˆ")
    
    def scan_directory(self, directory_path: str, pattern: str = "*.json") -> List[str]:
        """
        éæ­¸æƒæç›®éŒ„ï¼Œæ‰¾å‡ºæ‰€æœ‰ç¬¦åˆæ¢ä»¶çš„æª”æ¡ˆ
        
        Args:
            directory_path: ç›®éŒ„è·¯å¾‘
            pattern: æª”æ¡ˆåç¨±æ¨¡å¼ï¼ˆé è¨­: *.jsonï¼‰
            
        Returns:
            ç¬¦åˆæ¢ä»¶çš„æª”æ¡ˆè·¯å¾‘åˆ—è¡¨
        """
        directory = Path(directory_path)
        if not directory.exists():
            raise FileNotFoundError(f"ç›®éŒ„ä¸å­˜åœ¨: {directory_path}")
        
        if not directory.is_dir():
            raise NotADirectoryError(f"è·¯å¾‘ä¸æ˜¯ç›®éŒ„: {directory_path}")
        
        # éæ­¸æœå°‹æ‰€æœ‰ç¬¦åˆæ¨¡å¼çš„æª”æ¡ˆ
        files = list(directory.rglob(pattern))
        json_files = [str(f) for f in files if f.is_file()]
        
        print(f"ğŸ” æƒæç›®éŒ„: {directory_path}")
        print(f"   æ‰¾åˆ° {len(json_files)} å€‹ {pattern} æª”æ¡ˆ")
        
        return json_files
        
    def build_embeddings(self, corpus_path, force_rebuild=False):
        """
        ç‚ºæŒ‡å®šèªæ–™åº«å»ºç«‹åµŒå…¥å‘é‡
        
        Args:
            corpus_path: èªæ–™åº«æª”æ¡ˆè·¯å¾‘
            force_rebuild: æ˜¯å¦å¼·åˆ¶é‡å»ºï¼ˆå³ä½¿è³‡æ–™åº«å·²å­˜åœ¨ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸå»ºç«‹
        """
        try:
            # æå–èªæ–™åº«åç¨±å’Œç”Ÿæˆè³‡æ–™åº«åç¨±
            corpus_name = extract_corpus_name_from_path(corpus_path)
            db_name = f"{generate_db_name(corpus_name)}"
            collection_name = generate_collection_name(corpus_name)
            
            print(f"ğŸ”„ è™•ç†èªæ–™åº«: {corpus_name}")
            print(f"   æª”æ¡ˆè·¯å¾‘: {corpus_path}")
            print(f"   è³‡æ–™åº«åç¨±: {db_name}")
            print(f"   é›†åˆåç¨±: {collection_name}")
            
            # æª¢æŸ¥è³‡æ–™åº«æ˜¯å¦å·²å­˜åœ¨
            if Path(db_name).exists() and not force_rebuild:
                print(f"â„¹ï¸  è³‡æ–™åº« '{db_name}' å·²å­˜åœ¨ï¼Œè·³éå»ºç«‹ï¼ˆä½¿ç”¨ --force å¼·åˆ¶é‡å»ºï¼‰")
                return True
            
            # è¼‰å…¥èªæ–™åº«è³‡æ–™
            print("ğŸ”„ è¼‰å…¥èªæ–™åº«è³‡æ–™...")
            data = load_json_dataset(corpus_path)
            
            if not validate_corpus_structure(data):
                print(f"âŒ èªæ–™åº«çµæ§‹é©—è­‰å¤±æ•—: {corpus_path}")
                return False
            
            print(f"âœ… è¼‰å…¥äº† {len(data)} å€‹è¡¨æ ¼æ–‡ä»¶")
            
            # å»ºç«‹ Milvus å‘é‡è³‡æ–™åº«å®¢æˆ¶ç«¯
            print("ğŸ”„ åˆå§‹åŒ–å‘é‡è³‡æ–™åº«...")
            client = MilvusClient(db_name)
            
            # åˆªé™¤ç¾æœ‰é›†åˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰ä¸¦å»ºç«‹æ–°é›†åˆ
            if client.has_collection(collection_name=collection_name):
                client.drop_collection(collection_name=collection_name)
                print("ğŸ—‘ï¸  å·²åˆªé™¤ç¾æœ‰é›†åˆ")
            
            # å»ºç«‹æ–°çš„å‘é‡é›†åˆ
            client.create_collection(
                collection_name=collection_name,
                dimension=self.embedding_dim,
            )
            print("âœ… å»ºç«‹æ–°çš„å‘é‡é›†åˆ")
            
            # æº–å‚™æ–‡ä»¶è³‡æ–™
            print("ğŸ”„ é è™•ç†æ–‡ä»¶...")
            documents = []
            metadata = []
            
            for item in data:
                # é è™•ç†æ–‡å­—
                clean_text = preprocess_text(item['Text'])
                documents.append(clean_text)
                
                # ä¿å­˜å…ƒè³‡æ–™
                metadata.append({
                    'id': item['id'],
                    'filename': item.get('FileName', ''),
                    'sheet_name': item.get('SheetName', '')
                })
            
            # ç”ŸæˆåµŒå…¥å‘é‡
            print("ğŸ”„ ç”ŸæˆåµŒå…¥å‘é‡...")
            vectors = self.embedding_fn.encode(documents)['dense_vecs']  # BGE-M3 ä½¿ç”¨ encode æ–¹æ³•
            print(f"å‘é‡ç¶­åº¦: {len(vectors[0])}, å‘é‡æ•¸é‡: {len(vectors)}")
            
            # æº–å‚™æ’å…¥è³‡æ–™
            print("ğŸ”„ æº–å‚™æ’å…¥è³‡æ–™...")
            insert_data = []
            for i, (doc, vec, meta) in enumerate(zip(documents, vectors, metadata)):
                insert_data.append({
                    "id": i,
                    "vector": vec.astype('float32').tolist(),  # è½‰æ›ç‚º float32 ä¸¦è½‰ç‚º list
                    "text": doc,
                    "original_id": meta['id'],
                    "filename": meta['filename'],
                    "sheet_name": meta['sheet_name']
                })
            
            # æ’å…¥è³‡æ–™åˆ° Milvus
            print("ğŸ”„ æ’å…¥è³‡æ–™åˆ°å‘é‡è³‡æ–™åº«...")
            client.insert(collection_name=collection_name, data=insert_data)
            
            print(f"âœ… æˆåŠŸå»ºç«‹èªæ–™åº« '{corpus_name}' çš„åµŒå…¥å‘é‡")
            print(f"   è³‡æ–™åº«æª”æ¡ˆ: {db_name}")
            print(f"   è¨˜éŒ„æ•¸é‡: {len(insert_data)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ å»ºç«‹åµŒå…¥å‘é‡å¤±æ•—: {e}")
            # æ¸…ç†æå£çš„è³‡æ–™åº«æª”æ¡ˆ
            try:
                db_path = Path(generate_db_name(extract_corpus_name_from_path(corpus_path)))
                if db_path.exists():
                    db_path.unlink()
                    print(f"ğŸ—‘ï¸  å·²æ¸…ç†æå£çš„è³‡æ–™åº«æª”æ¡ˆ: {db_path}")
            except Exception as cleanup_error:
                print(f"âš ï¸  ç„¡æ³•æ¸…ç†æª”æ¡ˆ: {cleanup_error}")
            return False
    
    def build_directory_embeddings(self, directory_path: str, force_rebuild: bool = False) -> Dict[str, bool]:
        """
        éæ­¸æƒæç›®éŒ„ä¸¦ç‚ºæ‰€æœ‰ JSON æª”æ¡ˆå»ºç«‹åµŒå…¥å‘é‡
        
        Args:
            directory_path: ç›®éŒ„è·¯å¾‘
            force_rebuild: æ˜¯å¦å¼·åˆ¶é‡å»º
            
        Returns:
            å»ºç«‹çµæœå­—å…¸ {file_path: success}
        """
        try:
            # æƒæç›®éŒ„æ‰¾å‡ºæ‰€æœ‰ JSON æª”æ¡ˆ
            json_files = self.scan_directory(directory_path, "*.json")
            
            if not json_files:
                print("âš ï¸  åœ¨æŒ‡å®šç›®éŒ„ä¸­æ²’æœ‰æ‰¾åˆ°ä»»ä½• JSON æª”æ¡ˆ")
                return {}
            
            results = {}
            successful = 0
            
            print(f"\nğŸš€ é–‹å§‹è™•ç† {len(json_files)} å€‹æª”æ¡ˆ")
            
            for i, file_path in enumerate(json_files, 1):
                print(f"\n{'='*60}")
                print(f"è™•ç†æª”æ¡ˆ {i}/{len(json_files)}: {Path(file_path).name}")
                
                try:
                    success = self.build_embeddings(file_path, force_rebuild)
                    results[file_path] = success
                    if success:
                        successful += 1
                    
                except KeyboardInterrupt:
                    print("\nâš ï¸  ä½¿ç”¨è€…ä¸­æ–·æ“ä½œ")
                    break
                except Exception as e:
                    print(f"âŒ è™•ç†æª”æ¡ˆå¤±æ•—: {e}")
                    results[file_path] = False
            
            # é¡¯ç¤ºç¸½çµ
            print(f"\n{'='*60}")
            print("ç›®éŒ„æƒæå»ºç«‹å®Œæˆç¸½çµ:")
            print(f"ç›®éŒ„: {directory_path}")
            print(f"ç¸½æª”æ¡ˆæ•¸: {len(json_files)}")
            print(f"æˆåŠŸ: {successful}/{len(results)}")
            print(f"å¤±æ•—: {len(results) - successful}/{len(results)}")
            
            # è©³ç´°çµæœ
            if results:
                print("\nè©³ç´°çµæœ:")
                for file_path, success in results.items():
                    status = "âœ…" if success else "âŒ"
                    relative_path = Path(file_path).relative_to(directory_path)
                    print(f"  {status} {relative_path}")
            
            return results
            
        except Exception as e:
            print(f"âŒ ç›®éŒ„æƒæå¤±æ•—: {e}")
            return {}
    
    def build_all_embeddings(self, force_rebuild=False):
        """
        ç‚ºæ‰€æœ‰å¯ç”¨èªæ–™åº«å»ºç«‹åµŒå…¥å‘é‡
        
        Args:
            force_rebuild: æ˜¯å¦å¼·åˆ¶é‡å»º
            
        Returns:
            å»ºç«‹çµæœå­—å…¸ {corpus_name: success}
        """
        corpus_files = get_corpus_files()
        results = {}
        
        if not corpus_files:
            print("âš ï¸  æ²’æœ‰æ‰¾åˆ°ä»»ä½•èªæ–™åº«æª”æ¡ˆ")
            return results
        
        print(f"ğŸ”„ æ‰¾åˆ° {len(corpus_files)} å€‹èªæ–™åº«æª”æ¡ˆ")
        
        for i, corpus_info in enumerate(corpus_files, 1):
            print(f"\n{'='*60}")
            print(f"è™•ç†èªæ–™åº« {i}/{len(corpus_files)}")
            success = self.build_embeddings(corpus_info['path'], force_rebuild)
            results[corpus_info['name']] = success
        
        # é¡¯ç¤ºç¸½çµ
        print(f"\n{'='*60}")
        print("å»ºç«‹å®Œæˆç¸½çµ:")
        successful = sum(1 for success in results.values() if success)
        print(f"æˆåŠŸ: {successful}/{len(results)}")
        
        for corpus_name, success in results.items():
            status = "âœ…" if success else "âŒ"
            print(f"  {status} {corpus_name}")
        
        return results


def main():
    """ä¸»ç¨‹å¼"""
    parser = argparse.ArgumentParser(
        description='QGpT èªæ–™åº«åµŒå…¥å‘é‡å»ºç«‹å™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # ç‚ºæŒ‡å®šèªæ–™åº«å»ºç«‹åµŒå…¥å‘é‡
  python corpus_embedding_builder.py Corpora/Table1_mimo_table_length_variation/mimo_ch/1k_token.json
  
  # åˆ—å‡ºæ‰€æœ‰å¯ç”¨èªæ–™åº«
  python corpus_embedding_builder.py --list
  
  # ç‚ºæ‰€æœ‰èªæ–™åº«å»ºç«‹åµŒå…¥å‘é‡
  python corpus_embedding_builder.py --all
  
  # éæ­¸æƒæç›®éŒ„ä¸¦å»ºç«‹æ‰€æœ‰ JSON æª”æ¡ˆçš„åµŒå…¥å‘é‡
  python corpus_embedding_builder.py --scan-dir ./Corpora
  
  # å¼·åˆ¶é‡å»ºå·²å­˜åœ¨çš„è³‡æ–™åº«
  python corpus_embedding_builder.py --all --force
        """
    )
    
    parser.add_argument('corpus_path', nargs='?', help='èªæ–™åº«æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--list', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨èªæ–™åº«')
    parser.add_argument('--all', action='store_true', help='ç‚ºæ‰€æœ‰èªæ–™åº«å»ºç«‹åµŒå…¥å‘é‡')
    parser.add_argument('--scan-dir', metavar='DIR', help='éæ­¸æƒæç›®éŒ„ä¸¦ç‚ºæ‰€æœ‰ JSON æª”æ¡ˆå»ºç«‹åµŒå…¥å‘é‡')
    parser.add_argument('--force', action='store_true', help='å¼·åˆ¶é‡å»ºå·²å­˜åœ¨çš„è³‡æ–™åº«')
    parser.add_argument('--dim', type=int, default=1024, help='åµŒå…¥å‘é‡ç¶­åº¦ (é è¨­: 1024)')
    parser.add_argument('--model', default="bge_m3_flag", help='jina_colbert_v2 or bge_m3_flag (é è¨­: bge_m3_flag)')

    args = parser.parse_args()
    
    # åˆ—å‡ºæ‰€æœ‰å¯ç”¨èªæ–™åº«
    if args.list:
        corpus_files = get_corpus_files()
        if not corpus_files:
            print("æ²’æœ‰æ‰¾åˆ°ä»»ä½•èªæ–™åº«æª”æ¡ˆ")
            return
        
        print("å¯ç”¨çš„èªæ–™åº«æª”æ¡ˆ:")
        print("=" * 80)
        for i, corpus_info in enumerate(corpus_files, 1):
            print(f"{i:2d}. åç¨±: {corpus_info['name']}")
            print(f"     è·¯å¾‘: {corpus_info['path']}")
            print(f"     è³‡æ–™åº«: {corpus_info['db_name']}")
            print(f"     é›†åˆ: {corpus_info['collection_name']}")
            print()
        return
    
    # åˆå§‹åŒ–å»ºç«‹å™¨
    builder = CorpusEmbeddingBuilder(embedding_dim=args.dim, model=args.model)
    
    # éæ­¸æƒæç›®éŒ„å»ºç«‹åµŒå…¥å‘é‡
    if args.scan_dir:
        if not Path(args.scan_dir).exists():
            print(f"âŒ ç›®éŒ„ä¸å­˜åœ¨: {args.scan_dir}")
            sys.exit(1)
        
        results = builder.build_directory_embeddings(args.scan_dir, force_rebuild=args.force)
        
        # è¨­å®šé€€å‡ºä»£ç¢¼ï¼šå¦‚æœæœ‰ä»»ä½•å¤±æ•—å°±å›å‚³ 1
        failed_count = sum(1 for success in results.values() if not success)
        sys.exit(1 if failed_count > 0 else 0)
    
    # ç‚ºæ‰€æœ‰èªæ–™åº«å»ºç«‹åµŒå…¥å‘é‡
    if args.all:
        builder.build_all_embeddings(force_rebuild=args.force)
        return
    
    # ç‚ºæŒ‡å®šèªæ–™åº«å»ºç«‹åµŒå…¥å‘é‡
    if args.corpus_path:
        if not Path(args.corpus_path).exists():
            print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {args.corpus_path}")
            sys.exit(1)
        
        success = builder.build_embeddings(args.corpus_path, force_rebuild=args.force)
        sys.exit(0 if success else 1)
    
    # å¦‚æœæ²’æœ‰æä¾›åƒæ•¸ï¼Œé¡¯ç¤ºå¹«åŠ©
    parser.print_help()


if __name__ == "__main__":
    main()